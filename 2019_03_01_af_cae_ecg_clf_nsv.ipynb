{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019-03-01-af-cae-ecg-clf-nsv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfarb/cae_arrhythmia_classification/blob/master/2019_03_01_af_cae_ecg_clf_nsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_UWzynMY44u",
        "colab_type": "code",
        "outputId": "c9f25b35-6c64-46d8-a8d0-61c05b754c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm4LSL1qZfst",
        "colab_type": "code",
        "outputId": "58c56761-3fa3-4530-acd0-1c2261946855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "#import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1WWp26Kabb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProcessingData(object):\n",
        "    # Metódo Construtor\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        \n",
        "    # Função pra agrupar os dados de acordo com as classes    \n",
        "    def organize_data_labels(self, dataset_labels, label, dataset_length):\n",
        "        if label == 4:\n",
        "          rows = np.where(dataset_labels < 3)\n",
        "        else:  \n",
        "          rows = np.where(dataset_labels == label)\n",
        "        rows_list = list(rows)\n",
        "        rows = rows_list[0]\n",
        "        labels = rows_list[1]\n",
        "        samples = []\n",
        "        for i in range(0,len(rows)):\n",
        "            samples.append(self.dataset[rows[i],:])\n",
        "        samples_array = np.asarray(samples)\n",
        "        labels = np.reshape(labels,(len(labels),1))\n",
        "        \n",
        "        return samples_array, labels    \n",
        "        \n",
        "    # função para a normalização dos dados\n",
        "    def normalize_data(self, data, min, max):\n",
        "        return (data-min)/(max-min) # Cálculo para a normalização dos dados\n",
        "\n",
        "    # Função para converter os dados de volta a escala original\n",
        "    def original_scale_data(self, decoded, input, min, max):\n",
        "        decoded_original_scale = decoded * (max - min) + min\n",
        "        error = input - decoded_original_scale\n",
        "        return decoded_original_scale, error\n",
        "\n",
        "    # Função para salvar os resultados do treino em arquivo .csv\n",
        "    def save_results_train(self, loss, cae_label):\n",
        "        # Salva os resultados em um arquivo .csv\n",
        "        loss_path = \"/content/drive/My Drive/colab_apps/nsv/results/train/loss_%s.csv\" %(cae_label)\n",
        "        np.savetxt(loss_path, loss, delimiter=',', fmt='%s')\n",
        "        return\n",
        "    \n",
        "    # Função para salvar os resultados do teste (versão simples) em arquivo .csv\n",
        "    def save_results_test_simple(self, predicted, first_index, last_index):\n",
        "        # Salva os resultados em um arquivo .csv\n",
        "        predicted_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/simple/predicted_%s_%s.csv\" % (first_index, last_index)\n",
        "        np.savetxt(predicted_path, predicted, delimiter=',', fmt='%s')\n",
        "        \n",
        "    # Função para salvar os resultados do teste (versão completa) em arquivo .csv\n",
        "    def save_results_test_full(self, decoded, predicted, error, first_index, last_index):\n",
        "        # Salva os resultados em um arquivo .csv\n",
        "        decoded_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/full/decoded_%s_%s.csv\" %(first_index, last_index)\n",
        "        predicted_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/full/predicted_%s_%s.csv\" %(first_index, last_index)\n",
        "        error_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/full/error_%s_%s.csv\" %(first_index, last_index)\n",
        "        np.savetxt(decoded_path, decoded, delimiter=',', fmt='%s')\n",
        "        np.savetxt(predicted_path, predicted, delimiter=',', fmt='%s')\n",
        "        np.savetxt(error_path, error, delimiter=',', fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlNGndmmcdAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para treinar o modelo\n",
        "class AutoencoderTrain(object):\n",
        "    # Metódo Construtor\n",
        "    def __init__(self, input_train, output_train, data_length, data_dimension):\n",
        "        self.input_train = input_train\n",
        "        self.output_train = output_train\n",
        "        self.data_length = data_length\n",
        "        self.data_dimension = data_dimension\n",
        "    \n",
        "    # CAE para a reconstrução do sinal    \n",
        "    def convolutional_autoencoder_1d(self, kernel_size, epochs, optimizer_option, loss_option, cae_path):\n",
        "        x_train = np.expand_dims(self.input_train, axis=2) # Redimensionamento da entrada (treino) para o CAE\n",
        "        y_train = np.expand_dims(self.output_train, axis=2) # Redimensionamento da saída (treino) para o CAE\n",
        "        # Camadas de Convolução e Maxpooling para o Encoder    \n",
        "        input_signal = Input(shape=(self.data_length,self.data_dimension))\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(input_signal)\n",
        "        x = MaxPooling1D(2, padding='same')(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        x = MaxPooling1D(2, padding='same')(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        encoded = MaxPooling1D(3, padding='same')(x) # Saída do Encoder\n",
        "        \n",
        "        # Camadas de Convolução e Upsampling para o Decoder\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(encoded)\n",
        "        x = UpSampling1D(3)(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        x = UpSampling1D(2)(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        x = UpSampling1D(2)(x)\n",
        "        decoded = Conv1D(self.data_dimension, kernel_size, padding='same')(x) # Saída do Decoder\n",
        "        \n",
        "        # Compilação do Modelo\n",
        "        autoencoder = Model(input_signal, decoded)\n",
        "        autoencoder.compile(optimizer=optimizer_option, loss=loss_option)\n",
        "        \n",
        "        # Treinamento do Modelo\n",
        "        history_callback = autoencoder.fit(x_train,y_train,\n",
        "                         epochs=epochs,\n",
        "                         verbose = 0)\n",
        "        # Salva o histórico do erro para treino e teste\n",
        "        loss_train = history_callback.history[\"loss\"]\n",
        "\n",
        "        # Salva o modelo treinado em arquivo .h5\n",
        "        autoencoder.save(cae_path)\n",
        "        \n",
        "        # Saída do Treinamento\n",
        "        decoded_train = autoencoder.predict(x_train)\n",
        "        # Saída do Treinamento redimensionada\n",
        "        decoded_train_reshaped = (decoded_train.reshape(len(self.input_train), self.data_length))\n",
        "        # Erro de Treinamento\n",
        "        return decoded_train_reshaped, loss_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIB_Ysw3dUX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para rodar o treino\n",
        "class RunTrain(object):\n",
        "    def __init__(self, data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss):\n",
        "        self.data_length = data_length\n",
        "        self.data_dimension = data_dimension\n",
        "        self.min = min\n",
        "        self.max = max\n",
        "        self.kernel_size = kernel_size\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "\n",
        "    def run_cae(self, dataset, dataset_labels, cae_id):    \n",
        "        cae_label = str(cae_id)\n",
        "        cae_path = \"/content/drive/My Drive/colab_apps/nsv/models/cae_%s.h5\" %(cae_label)\n",
        "        processing = ProcessingData(dataset)\n",
        "        samples, labels = processing.organize_data_labels(dataset_labels, cae_id, len(dataset))\n",
        "        # Normalização das entradas e saídas\n",
        "        # x = processing.normalize_data(samples, self.min, self.max)\n",
        "        x = samples\n",
        "        y = x\n",
        "        # CAE\n",
        "        auto_encoder = AutoencoderTrain(x, y, self.data_length, self.data_dimension)\n",
        "        decoded, loss = auto_encoder.convolutional_autoencoder_1d(self.kernel_size, \n",
        "                                                                  self.epochs, \n",
        "                                                                  self.optimizer, \n",
        "                                                                  self.loss, \n",
        "                                                                  cae_path)\n",
        "        #decoded_original_scale, error = processing.original_scale_data(decoded, x, min, max)\n",
        "        processing.save_results_train(loss, cae_label)\n",
        "        return decoded, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDKLhwqndCle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para testar o modelo\n",
        "class AutoencoderTest(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "      \n",
        "    def autoencoder(self, data, min, max, model):\n",
        "        data_proc = ProcessingData(data)\n",
        "        data_original = data\n",
        "#        data_norm = data_proc.normalize_data(data_original)\n",
        "        data_norm = data\n",
        "        data_reshaped = np.expand_dims(data_norm, axis=2)\n",
        "        z = data_reshaped.T\n",
        "        data_input = np.expand_dims(z, axis=2)\n",
        "        predict_model_a = model.predict(data_input)\n",
        "        decoded_reshaped = (predict_model_a.reshape(1, 180))\n",
        "#        data_decoded = decoded_reshaped*(max - min) + min\n",
        "        return decoded_reshaped\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBi8ay7ddgNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para rodar o teste\n",
        "class RunTest(object):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "    \n",
        "    def run_competitive_cae(self, data_index, min, max, mode, model_a, model_b, model_c):\n",
        "        cae = AutoencoderTest()\n",
        "        data_decoded_a = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "                                         model_a)\n",
        "        data_dim = np.expand_dims(self.dataset[data_index,:], axis=2)\n",
        "        data_reshaped = data_dim.T\n",
        "        msq_a = mean_squared_error(data_reshaped, data_decoded_a)\n",
        "        data_decoded_b = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "                                         model_b)\n",
        "        msq_b = mean_squared_error(data_reshaped, data_decoded_b)\n",
        "        data_decoded_c = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "                                         model_c)\n",
        "        msq_c = mean_squared_error(data_reshaped, data_decoded_c)\n",
        "        #data_decoded_d = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "        #                                 model_d)\n",
        "        #msq_d = mean_squared_error(data_reshaped, data_decoded_d)\n",
        "        msq_vector = np.array([msq_a, msq_b, msq_c])\n",
        "        if mode == 0: # Modo Simples\n",
        "            msq_min_index = np.argmin(msq_vector)\n",
        "            return msq_min_index\n",
        "        elif mode == 1: # Modo Completo\n",
        "            msq_min = msq_vector.min()\n",
        "            msq_min_index = np.argmin(msq_vector)\n",
        "            decoded_vector = np.array([data_decoded_a, data_decoded_b, \n",
        "                                       data_decoded_c])\n",
        "            return msq_min_index, msq_vector, decoded_vector\n",
        "        else:\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnKa1YVYqzOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainCae(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def main(self, cae_id, epochs):\n",
        "    # Carrega a Base de Dados\n",
        "    dataset_train = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/signals/DS1_signals.csv\",delimiter=\",\")\n",
        "    dataset_labels_train = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/labels/DS1_labels.csv\",delimiter=\",\")\n",
        "    dataset_labels_train = np.reshape(dataset_labels_train,(len(dataset_labels_train),1))\n",
        "    #cae_id = 'n'\n",
        "    # Variáveis para a configuração da CAE\n",
        "    data_length = len(dataset_train.T) # Tamanho do sinal em número de amostras\n",
        "    kernel_size =  20 # Tamanho do Kernel (Janela) de Convolução\n",
        "    epochs = epochs # Quantidade de Épocas para o Treinamento da Rede\n",
        "    data_dimension = 1 # Dimensão dos Dados\n",
        "    optimizer = 'adamax'\n",
        "    loss = 'mean_squared_error'\n",
        "    min = np.amin(dataset_train)\n",
        "    max = np.amax(dataset_train)\n",
        "    # Divisão da Base de Dados em Grupos de acordo com as classes\n",
        "    #processing = ProcessingData(dataset_train)\n",
        "\n",
        "    cae_id = cae_id # 0 = N, 1 = S, 2 = V, 3 = F e 4[?] = Q\n",
        "    # Treina a Rede N\n",
        "    if cae_id == 0:\n",
        "        train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "        decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede S\n",
        "    elif cae_id == 1:\n",
        "        train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "        decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede V\n",
        "    elif cae_id == 2:\n",
        "        train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "        decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede F    \n",
        "    #elif cae_id == 3:\n",
        "    #    train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "    #    decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede Q\n",
        "    # Apenas para finalizar a condicional caso entre com algum valor diferente    \n",
        "    else:\n",
        "        pass\n",
        "    # To show CAEs DataFrame with EQM and Epochs    \n",
        "    loss_n_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/ens/results/train/loss_0.csv\",header=None)\n",
        "    loss_s_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/nsv/results/train/loss_1.csv\",header=None)\n",
        "    loss_v_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/nsv/results/train/loss_2.csv\",header=None)\n",
        "    #loss_f_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/results/train/loss_3.csv\",header=None)\n",
        "    loss_n = loss_n_data.iloc[-1]\n",
        "    loss_s = loss_s_data.iloc[-1]\n",
        "    loss_v = loss_v_data.iloc[-1]\n",
        "    #loss_f = loss_f_data.iloc[-1]\n",
        "    loss_n_epochs = len(loss_n_data)\n",
        "    loss_s_epochs = len(loss_s_data)\n",
        "    loss_v_epochs = len(loss_v_data)\n",
        "    #loss_f_epochs = len(loss_f_data)\n",
        "    epochs_values = [loss_n_epochs, loss_s_epochs, loss_v_epochs]\n",
        "    df_train = pd.DataFrame([loss_n, loss_s, loss_v], index=['Rede N', 'Rede S', 'Rede V'])\n",
        "    df_train = df_train.assign(Épocas = epochs_values)\n",
        "    df_train.columns = ['EQM', 'Épocas']\n",
        "    print(df_train.head())\n",
        "    df_train.to_csv('/content/drive/My Drive/colab_apps/nsv/results/train/train_parameters.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU77w3DvwCAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCae(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def main(self, first_index, last_index):\n",
        "    startTime = datetime.now()\n",
        "    # Carrega a Base de Dados DS2\n",
        "    dataset_test = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/signals/DS2_signals.csv\",delimiter=\",\")\n",
        "    dataset_labels_test = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/labels/DS2_labels.csv\", delimiter=\",\")\n",
        "    dataset_labels_test = np.reshape(dataset_labels_test, (len(dataset_labels_test), 1))\n",
        "    net_type = 4\n",
        "    data_proc = ProcessingData(dataset_test)\n",
        "    dataset_test, dataset_labels_test_num = data_proc.organize_data_labels(dataset_labels_test, net_type, len(dataset_test))\n",
        "    labels_rows, labels_num = np.where(dataset_labels_test < 3)\n",
        "    labels_test = []\n",
        "    for index in range(0, len(labels_rows)):\n",
        "      labels_test.append(dataset_labels_test[labels_rows[index]])\n",
        "    # Carrega os modelos salvos\n",
        "    model_a = load_model('/content/drive/My Drive/colab_apps/ens/models/cae_0.h5')\n",
        "    model_b = load_model('/content/drive/My Drive/colab_apps/nsv/models/cae_1.h5')\n",
        "    model_c = load_model('/content/drive/My Drive/colab_apps/nsv/models/cae_2.h5')\n",
        "    #model_d = load_model('/content/drive/My Drive/colab_apps/models/cae_3.h5')\n",
        "    mode = 1\n",
        "    # Valores de Minimo e Máximo do Conjunto de Dados\n",
        "    max = 1024\n",
        "    min = -1024\n",
        "    # Indices onde se inicia e encerra as amostras para o teste\n",
        "    first_index = first_index\n",
        "    last_index = last_index\n",
        "    # Correção para começar no indice correto da Matriz\n",
        "    initial_index = first_index-1\n",
        "    # Array com quais indices o sistema será testado\n",
        "    data_array = np.arange(initial_index, last_index)\n",
        "    # Instanciamento para a execução das redes\n",
        "    cae = RunTest(dataset_test)\n",
        "    data_save = ProcessingData(dataset_test)\n",
        "    # Execução das Redes\n",
        "    if mode == 0: # Modo Simples\n",
        "        # Matrizes para salvar os resultados\n",
        "        predicted_mat = []\n",
        "        for data_index in data_array:\n",
        "            predicted = cae.run_competitive_cae(data_index, min, max, mode, model_a, model_b, model_c)\n",
        "            predicted_mat.append(predicted)\n",
        "            #print(data_index)\n",
        "        data_save.save_results_test_simple(predicted_mat, first_index, last_index)\n",
        "    elif mode == 1: # Modo Completo\n",
        "        # Matrizes para salvar os resultados\n",
        "        error_mat = []\n",
        "        predicted_mat = []\n",
        "        decoded_mat = []\n",
        "        for data_index in data_array:\n",
        "            predicted, error, decoded = cae.run_competitive_cae(data_index, min, max, mode, model_a, model_b, model_c)\n",
        "            error_mat.append(error)\n",
        "            predicted_mat.append(predicted)\n",
        "            decoded_mat.append(decoded)\n",
        "        # Converte decoded para um array\n",
        "        decoded_array = np.asarray(decoded_mat)\n",
        "        decoded_array = decoded_array.reshape((3, 180))\n",
        "        print(predicted_mat)\n",
        "        print(error_mat)\n",
        "        print(decoded_array)\n",
        "        # Salva os resultados\n",
        "        data_save.save_results_test_full(decoded_array, predicted_mat, error_mat, first_index, last_index)\n",
        "    else:\n",
        "        pass\n",
        "    #print(\"Tempo de Execução = \", datetime.now() - startTime)\n",
        "    # Armazena em um vetor linha as classes originais e as preditas\n",
        "    data_true = labels_test\n",
        "    pred_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/simple/predicted_%s_%s.csv\" %(first_index, last_index)\n",
        "    pred_mat = np.loadtxt(pred_path, delimiter=\",\")\n",
        "    pred_mat = np.reshape(pred_mat, (len(pred_mat), 1))\n",
        "    pred_mat = pred_mat.T\n",
        "    #data_true = data_true.tolist()\n",
        "    pred_mat = pred_mat.tolist()\n",
        "    #data_true = data_true[0]\n",
        "    data_true = data_true[initial_index:last_index]\n",
        "    pred_mat = pred_mat[0]\n",
        "    # Calcula Acurácia, Sensibilidade e +P\n",
        "    accuracy = accuracy_score(data_true, pred_mat)\n",
        "    print('Acc = ', accuracy)\n",
        "    recall = recall_score(data_true, pred_mat, average='macro') \n",
        "    print('Sen = ', recall)\n",
        "    #recall_class = recall_score(data_true, pred_mat, average=None) \n",
        "    #print('Sen_C = ', recall_class)\n",
        "    #precision_class = precision_score(data_true, pred_mat, average=None) \n",
        "    #print('+P = ', precision_class)\n",
        "    precision, recall, fscore, support = score(data_true, pred_mat)\n",
        "    #print('+P: {}'.format(precision))\n",
        "    #print('Sen: {}'.format(recall))\n",
        "    recall_values = [precision[0], precision[1], precision[2]]\n",
        "    df_score = pd.DataFrame([recall[0], recall[1], recall[2]], index=['N', 'S', 'V'])\n",
        "    df_score = df_score.assign(P = recall_values)\n",
        "    df_score.columns = ['Sen', 'P']\n",
        "    print(df_score.head())\n",
        "    #df_test = pd.DataFrame([recall_class[0], recall_class[1], recall_class[2], recall_class[3]], \n",
        "    #                       index=['Classe N', 'Classe S', 'Classe V', 'Classe F'])\n",
        "    #df_test.columns = ['Sen', 'PPV']\n",
        "    #df_test = df_test.assign(PPV = precision_class)\n",
        "    #print(df_test.head())\n",
        "    #df_test.to_csv('/content/drive/My Drive/colab_apps/results/test/test_sen_p.csv')\n",
        "\n",
        "    cf = confusion_matrix(data_true, pred_mat)\n",
        "    #cf_cm = pd.DataFrame(cf, index = [i for i in \"NSVF\"],\n",
        "    #                  columns = [i for i in \"NSVF\"])\n",
        "    #plt.figure(figsize=(6, 6))\n",
        "    #sns_confmat = sns.heatmap(cf_cm, cbar = False, annot=True, fmt='g')\n",
        "    #fig_path = \"/content/drive/My Drive/colab_apps/results/test/confmat_%s_%s.png\" %(first_index, last_index)\n",
        "    #sns_confmat.savefig(fig_path)\n",
        "    classes = ['N','S','V']\n",
        "    plt.imshow(cf, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Matriz de Confusão\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cf.max() / 2.\n",
        "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
        "        plt.text(j, i, format(cf[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cf[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('Classes Preditas')\n",
        "    plt.xlabel('Classes Originais')\n",
        "    plt.tight_layout()\n",
        "    fig_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/confmat_%s.png\" %(accuracy)\n",
        "    plt.savefig(fig_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlyfvp7wj0LF",
        "colab_type": "code",
        "outputId": "0d4f9fbe-ea82-4f03-fae3-a77f10b2ebcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "cae_train = TrainCae()\n",
        "cae_train.main(1,7900) # cae_id, epochs. Para 1, o valor ideal do EQM é próximo de 120"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             EQM  Épocas\n",
            "Rede N  0.000124     300\n",
            "Rede S  0.000121    7900\n",
            "Rede V  0.000144     450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Np90cNKjYj",
        "colab_type": "code",
        "outputId": "661a2044-9b53-4776-80d3-85bc6522a92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2276
        }
      },
      "source": [
        "cae_test = TestCae()\n",
        "cae_test.main(1906, 1906) #49303"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2]\n",
            "[array([0.00082691, 0.00080681, 0.00036797])]\n",
            "[[0.95897627 0.9602603  0.95127964 0.9509216  0.9558284  0.9560146\n",
            "  0.95455074 0.95563525 0.95780504 0.9592822  0.9612157  0.9632263\n",
            "  0.9644496  0.9658858  0.96866274 0.9697824  0.97196025 0.9739761\n",
            "  0.9741979  0.97509766 0.97406256 0.9728983  0.9735108  0.9728156\n",
            "  0.9707221  0.97147065 0.9750744  0.9774318  0.9829928  0.98670626\n",
            "  0.9881355  0.9895144  0.98691446 0.98453414 0.9824056  0.97969306\n",
            "  0.97572744 0.97539926 0.9790303  0.98245496 0.98877335 0.99299204\n",
            "  0.9950324  0.99456304 0.9904878  0.9844169  0.9750689  0.9675649\n",
            "  0.95948887 0.9556709  0.95481163 0.95661116 0.9585098  0.9602809\n",
            "  0.9590155  0.95414966 0.94656134 0.93429756 0.9183362  0.90313953\n",
            "  0.8878195  0.8752389  0.86208296 0.85412693 0.8459556  0.84167117\n",
            "  0.8372585  0.8353543  0.8349016  0.8335411  0.8340876  0.83145386\n",
            "  0.8288482  0.8224025  0.8103501  0.7983338  0.78556085 0.7748803\n",
            "  0.7753012  0.7825137  0.8030745  0.83247364 0.8675541  0.9038668\n",
            "  0.9438964  0.97167516 0.9914312  1.0047636  1.0111651  1.0146607\n",
            "  1.0181284  1.0187191  1.0179926  1.0170994  1.0154673  1.0144023\n",
            "  1.015777   1.0175154  1.0209788  1.025068   1.0300492  1.0336561\n",
            "  1.037183   1.0393281  1.0406581  1.0423418  1.0445234  1.0472963\n",
            "  1.0513353  1.0553224  1.0589886  1.0628737  1.0660604  1.068257\n",
            "  1.0693552  1.0689993  1.067814   1.06507    1.0611342  1.0572455\n",
            "  1.053543   1.0502747  1.0465292  1.0442704  1.0416158  1.0399514\n",
            "  1.0389212  1.0384699  1.0392238  1.040247   1.0416723  1.0425828\n",
            "  1.043389   1.0423337  1.0393206  1.0358732  1.0314909  1.0282458\n",
            "  1.0269026  1.027451   1.0304703  1.0353005  1.0416168  1.0475858\n",
            "  1.0535731  1.057494   1.0606072  1.0617257  1.0624456  1.0626866\n",
            "  1.0632511  1.0641636  1.0649825  1.0669318  1.0683715  1.0701653\n",
            "  1.070507   1.0713325  1.0745584  1.0759535  1.0782539  1.0801072\n",
            "  1.0809205  1.0801182  1.0776509  1.0736551  1.0689518  1.0653963\n",
            "  1.0616049  1.0622742  1.0611857  1.0620974  1.0760225  1.0864651\n",
            "  1.0824262  1.0797536  1.0693763  1.0569249  1.0601697  1.0465028 ]\n",
            " [0.97203296 0.9761353  0.9736899  0.96927774 0.9699481  0.96842235\n",
            "  0.9566315  0.9456616  0.9440533  0.94573444 0.9525892  0.9602169\n",
            "  0.965162   0.9678525  0.96625996 0.96215063 0.9559076  0.94942445\n",
            "  0.9464955  0.94742167 0.9514282  0.9583385  0.9688411  0.97645557\n",
            "  0.97657335 0.9736937  0.965636   0.95888877 0.9592166  0.9608225\n",
            "  0.96407384 0.9685946  0.9665691  0.9649176  0.9625155  0.95863026\n",
            "  0.9630544  0.9670018  0.96976256 0.97414494 0.9799121  0.98658335\n",
            "  0.9863816  0.98598003 0.9809765  0.974865   0.9677481  0.9602161\n",
            "  0.9626865  0.96752685 0.97718525 0.9882065  1.0019938  1.0095043\n",
            "  1.0095236  0.997198   0.96871376 0.9308429  0.8901684  0.84860975\n",
            "  0.82529104 0.8043799  0.7942344  0.7844616  0.7752931  0.76771975\n",
            "  0.7639981  0.7630826  0.7734287  0.7843888  0.7989626  0.8127339\n",
            "  0.81742734 0.81973374 0.8177744  0.81310225 0.8052944  0.80302\n",
            "  0.80110544 0.8111677  0.8326754  0.8625917  0.8945881  0.92962134\n",
            "  0.944464   0.9599678  0.9734919  0.9857131  0.9984113  1.0097271\n",
            "  1.0163181  1.0194422  1.0165888  1.0116533  1.0024992  0.99629086\n",
            "  0.98781955 0.9847421  0.99355394 1.0066233  1.0110779  1.0166193\n",
            "  1.0223851  1.0257202  1.0267894  1.0255249  1.0257703  1.0249774\n",
            "  1.0291694  1.0336912  1.0373254  1.0432798  1.0455934  1.0491045\n",
            "  1.0552033  1.0606055  1.0578686  1.0540503  1.0459783  1.038395\n",
            "  1.034364   1.0300423  1.0250363  1.0175414  1.015955   1.0137101\n",
            "  1.0119224  1.0113176  1.0191127  1.0292991  1.0401208  1.052669\n",
            "  1.0529385  1.0529912  1.0497046  1.0461615  1.0403883  1.0349711\n",
            "  1.0362045  1.0385091  1.044198   1.0530351  1.0636902  1.0752496\n",
            "  1.0839177  1.0904673  1.0909033  1.0906461  1.0849061  1.0796671\n",
            "  1.0797819  1.0819278  1.0841917  1.088214   1.0920366  1.0939835\n",
            "  1.0948539  1.093937   1.0883167  1.0837392  1.0858614  1.087225\n",
            "  1.0893736  1.0900943  1.08391    1.078385   1.0734596  1.0685136\n",
            "  1.0719174  1.0748782  1.0781107  1.0787233  1.0728077  1.0673431\n",
            "  1.0636402  1.0586587  1.052956   1.0453047  1.0454443  1.0402535 ]\n",
            " [0.96236235 0.96025395 0.96005577 0.9584898  0.95792776 0.9576681\n",
            "  0.959578   0.96072096 0.9603343  0.9614586  0.9628416  0.9646445\n",
            "  0.96673596 0.96866214 0.97027475 0.97175014 0.97321427 0.9740103\n",
            "  0.974083   0.9738914  0.9722311  0.9707356  0.969011   0.9667724\n",
            "  0.96375906 0.9611192  0.9580778  0.9552276  0.95417625 0.9524095\n",
            "  0.9519442  0.9516481  0.95098585 0.9511453  0.95092094 0.9515227\n",
            "  0.95086044 0.95142627 0.9515975  0.95161414 0.95305276 0.95336163\n",
            "  0.9544233  0.95505935 0.957013   0.95790225 0.95839155 0.9599128\n",
            "  0.96073407 0.96225494 0.96104383 0.96107304 0.9585409  0.9561931\n",
            "  0.94799024 0.9404641  0.9298758  0.9175843  0.9043603  0.88912183\n",
            "  0.86887735 0.8507817  0.8321309  0.81480587 0.7985346  0.7860587\n",
            "  0.77787626 0.7720518  0.77235866 0.7737335  0.7754489  0.78130096\n",
            "  0.7886753  0.7961366  0.805205   0.81392795 0.82036316 0.8284606\n",
            "  0.83894926 0.84711254 0.85863626 0.86978394 0.88489616 0.89834857\n",
            "  0.9177114  0.9330993  0.9503163  0.9664072  0.9799511  0.9917051\n",
            "  0.99906063 1.0052965  1.0081642  1.010118   1.0131915  1.0122613\n",
            "  1.0150292  1.014794   1.0154582  1.0159582  1.0167412  1.0170166\n",
            "  1.0166692  1.0172956  1.0162733  1.015606   1.0125386  1.009671\n",
            "  1.0070616  1.004225   1.0035083  1.0014709  0.9987223  0.99748796\n",
            "  0.99878967 0.99994427 1.0034556  1.0069783  1.0102309  1.0145252\n",
            "  1.0186585  1.0227764  1.0283803  1.0326536  1.0348148  1.0375426\n",
            "  1.039066   1.0398545  1.0399973  1.0400645  1.0418923  1.0418544\n",
            "  1.0411937  1.0404106  1.0398822  1.0391719  1.0402387  1.0402915\n",
            "  1.0415063  1.0427651  1.0425494  1.0439639  1.0453254  1.0471368\n",
            "  1.0503995  1.0533009  1.0559468  1.0585971  1.0645361  1.0677806\n",
            "  1.0728042  1.0769408  1.0778648  1.0803747  1.0817425  1.0831726\n",
            "  1.0835321  1.0847327  1.0850556  1.0846686  1.0871699  1.086663\n",
            "  1.0876253  1.0875976  1.087893   1.0869522  1.0835879  1.082561\n",
            "  1.079923   1.0795531  1.0787096  1.077557   1.072205   1.0703728\n",
            "  1.0726576  1.0704494  1.0747684  1.075233   1.0820233  1.0822806 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dc6d58c35fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcae_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestCae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcae_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1906\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1906\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#49303\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-2a51885ce771>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, first_index, last_index)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdata_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mpred_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/My Drive/colab_apps/nsv/results/test/simple/predicted_%s_%s.csv\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mpred_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mpred_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mpred_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /content/drive/My Drive/colab_apps/nsv/results/test/simple/predicted_1906_1906.csv not found."
          ]
        }
      ]
    }
  ]
}