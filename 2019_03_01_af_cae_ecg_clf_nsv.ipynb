{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019-03-01-af-cae-ecg-clf-nsv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexfarb/cae_arrhythmia_classification/blob/master/2019_03_01_af_cae_ecg_clf_nsv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_UWzynMY44u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm4LSL1qZfst",
        "colab_type": "code",
        "outputId": "58c56761-3fa3-4530-acd0-1c2261946855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "#import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support as score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1WWp26Kabb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProcessingData(object):\n",
        "    # Metódo Construtor\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        \n",
        "    # Função pra agrupar os dados de acordo com as classes    \n",
        "    def organize_data_labels(self, dataset_labels, label, dataset_length):\n",
        "        if label == 4:\n",
        "          rows = np.where(dataset_labels < 3)\n",
        "        else:  \n",
        "          rows = np.where(dataset_labels == label)\n",
        "        rows_list = list(rows)\n",
        "        rows = rows_list[0]\n",
        "        labels = rows_list[1]\n",
        "        samples = []\n",
        "        for i in range(0,len(rows)):\n",
        "            samples.append(self.dataset[rows[i],:])\n",
        "        samples_array = np.asarray(samples)\n",
        "        labels = np.reshape(labels,(len(labels),1))\n",
        "        \n",
        "        return samples_array, labels    \n",
        "        \n",
        "    # função para a normalização dos dados\n",
        "    def normalize_data(self, data, min, max):\n",
        "        return (data-min)/(max-min) # Cálculo para a normalização dos dados\n",
        "\n",
        "    # Função para converter os dados de volta a escala original\n",
        "    def original_scale_data(self, decoded, input, min, max):\n",
        "        decoded_original_scale = decoded * (max - min) + min\n",
        "        error = input - decoded_original_scale\n",
        "        return decoded_original_scale, error\n",
        "\n",
        "    # Função para salvar os resultados do treino em arquivo .csv\n",
        "    def save_results_train(self, loss, cae_label):\n",
        "        # Salva os resultados em um arquivo .csv\n",
        "        loss_path = \"/content/drive/My Drive/colab_apps/nsv/results/train/loss_%s.csv\" %(cae_label)\n",
        "        np.savetxt(loss_path, loss, delimiter=',', fmt='%s')\n",
        "        return\n",
        "    \n",
        "    # Função para salvar os resultados do teste (versão simples) em arquivo .csv\n",
        "    def save_results_test_simple(self, predicted, first_index, last_index):\n",
        "        # Salva os resultados em um arquivo .csv\n",
        "        predicted_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/simple/predicted_%s_%s.csv\" % (first_index, last_index)\n",
        "        np.savetxt(predicted_path, predicted, delimiter=',', fmt='%s')\n",
        "        \n",
        "    # Função para salvar os resultados do teste (versão completa) em arquivo .csv\n",
        "    def save_results_test_full(self, decoded, predicted, error, first_index, last_index):\n",
        "        # Salva os resultados em um arquivo .csv\n",
        "        decoded_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/full/decoded_%s_%s.csv\" %(first_index, last_index)\n",
        "        predicted_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/full/predicted_%s_%s.csv\" %(first_index, last_index)\n",
        "        error_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/full/error_%s_%s.csv\" %(first_index, last_index)\n",
        "        np.savetxt(decoded_path, decoded, delimiter=',', fmt='%s')\n",
        "        np.savetxt(predicted_path, predicted, delimiter=',', fmt='%s')\n",
        "        np.savetxt(error_path, error, delimiter=',', fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlNGndmmcdAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para treinar o modelo\n",
        "class AutoencoderTrain(object):\n",
        "    # Metódo Construtor\n",
        "    def __init__(self, input_train, output_train, data_length, data_dimension):\n",
        "        self.input_train = input_train\n",
        "        self.output_train = output_train\n",
        "        self.data_length = data_length\n",
        "        self.data_dimension = data_dimension\n",
        "    \n",
        "    # CAE para a reconstrução do sinal    \n",
        "    def convolutional_autoencoder_1d(self, kernel_size, epochs, optimizer_option, loss_option, cae_path):\n",
        "        x_train = np.expand_dims(self.input_train, axis=2) # Redimensionamento da entrada (treino) para o CAE\n",
        "        y_train = np.expand_dims(self.output_train, axis=2) # Redimensionamento da saída (treino) para o CAE\n",
        "        # Camadas de Convolução e Maxpooling para o Encoder    \n",
        "        input_signal = Input(shape=(self.data_length,self.data_dimension))\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(input_signal)\n",
        "        x = MaxPooling1D(2, padding='same')(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        x = MaxPooling1D(2, padding='same')(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        encoded = MaxPooling1D(3, padding='same')(x) # Saída do Encoder\n",
        "        \n",
        "        # Camadas de Convolução e Upsampling para o Decoder\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(encoded)\n",
        "        x = UpSampling1D(3)(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        x = UpSampling1D(2)(x)\n",
        "        x = Conv1D(self.data_dimension, kernel_size, padding='same')(x)\n",
        "        x = UpSampling1D(2)(x)\n",
        "        decoded = Conv1D(self.data_dimension, kernel_size, padding='same')(x) # Saída do Decoder\n",
        "        \n",
        "        # Compilação do Modelo\n",
        "        autoencoder = Model(input_signal, decoded)\n",
        "        autoencoder.compile(optimizer=optimizer_option, loss=loss_option)\n",
        "        \n",
        "        # Treinamento do Modelo\n",
        "        history_callback = autoencoder.fit(x_train,y_train,\n",
        "                         epochs=epochs,\n",
        "                         verbose = 0)\n",
        "        # Salva o histórico do erro para treino e teste\n",
        "        loss_train = history_callback.history[\"loss\"]\n",
        "\n",
        "        # Salva o modelo treinado em arquivo .h5\n",
        "        autoencoder.save(cae_path)\n",
        "        \n",
        "        # Saída do Treinamento\n",
        "        decoded_train = autoencoder.predict(x_train)\n",
        "        # Saída do Treinamento redimensionada\n",
        "        decoded_train_reshaped = (decoded_train.reshape(len(self.input_train), self.data_length))\n",
        "        # Erro de Treinamento\n",
        "        return decoded_train_reshaped, loss_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIB_Ysw3dUX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para rodar o treino\n",
        "class RunTrain(object):\n",
        "    def __init__(self, data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss):\n",
        "        self.data_length = data_length\n",
        "        self.data_dimension = data_dimension\n",
        "        self.min = min\n",
        "        self.max = max\n",
        "        self.kernel_size = kernel_size\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "\n",
        "    def run_cae(self, dataset, dataset_labels, cae_id):    \n",
        "        cae_label = str(cae_id)\n",
        "        cae_path = \"/content/drive/My Drive/colab_apps/nsv/models/cae_%s.h5\" %(cae_label)\n",
        "        processing = ProcessingData(dataset)\n",
        "        samples, labels = processing.organize_data_labels(dataset_labels, cae_id, len(dataset))\n",
        "        # Normalização das entradas e saídas\n",
        "        # x = processing.normalize_data(samples, self.min, self.max)\n",
        "        x = samples\n",
        "        y = x\n",
        "        # CAE\n",
        "        auto_encoder = AutoencoderTrain(x, y, self.data_length, self.data_dimension)\n",
        "        decoded, loss = auto_encoder.convolutional_autoencoder_1d(self.kernel_size, \n",
        "                                                                  self.epochs, \n",
        "                                                                  self.optimizer, \n",
        "                                                                  self.loss, \n",
        "                                                                  cae_path)\n",
        "        #decoded_original_scale, error = processing.original_scale_data(decoded, x, min, max)\n",
        "        processing.save_results_train(loss, cae_label)\n",
        "        return decoded, loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDKLhwqndCle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para testar o modelo\n",
        "class AutoencoderTest(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "      \n",
        "    def autoencoder(self, data, min, max, model):\n",
        "        data_proc = ProcessingData(data)\n",
        "        data_original = data\n",
        "#        data_norm = data_proc.normalize_data(data_original)\n",
        "        data_norm = data\n",
        "        data_reshaped = np.expand_dims(data_norm, axis=2)\n",
        "        z = data_reshaped.T\n",
        "        data_input = np.expand_dims(z, axis=2)\n",
        "        predict_model_a = model.predict(data_input)\n",
        "        decoded_reshaped = (predict_model_a.reshape(1, 180))\n",
        "#        data_decoded = decoded_reshaped*(max - min) + min\n",
        "        return decoded_reshaped\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBi8ay7ddgNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classe para rodar o teste\n",
        "class RunTest(object):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "    \n",
        "    def run_competitive_cae(self, data_index, min, max, mode, model_a, model_b, model_c):\n",
        "        cae = AutoencoderTest()\n",
        "        data_decoded_a = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "                                         model_a)\n",
        "        data_dim = np.expand_dims(self.dataset[data_index,:], axis=2)\n",
        "        data_reshaped = data_dim.T\n",
        "        msq_a = mean_squared_error(data_reshaped, data_decoded_a)\n",
        "        data_decoded_b = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "                                         model_b)\n",
        "        msq_b = mean_squared_error(data_reshaped, data_decoded_b)\n",
        "        data_decoded_c = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "                                         model_c)\n",
        "        msq_c = mean_squared_error(data_reshaped, data_decoded_c)\n",
        "        #data_decoded_d = cae.autoencoder(self.dataset[data_index,:], min, max, \n",
        "        #                                 model_d)\n",
        "        #msq_d = mean_squared_error(data_reshaped, data_decoded_d)\n",
        "        msq_vector = np.array([msq_a, msq_b, msq_c])\n",
        "        if mode == 0: # Modo Simples\n",
        "            msq_min_index = np.argmin(msq_vector)\n",
        "            return msq_min_index\n",
        "        elif mode == 1: # Modo Completo\n",
        "            msq_min = msq_vector.min()\n",
        "            msq_min_index = np.argmin(msq_vector)\n",
        "            decoded_vector = np.array([data_decoded_a, data_decoded_b, \n",
        "                                       data_decoded_c])\n",
        "            return msq_min_index, msq_vector, decoded_vector\n",
        "        else:\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnKa1YVYqzOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainCae(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def main(self, cae_id, epochs):\n",
        "    # Carrega a Base de Dados\n",
        "    dataset_train = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/signals/DS1_signals.csv\",delimiter=\",\")\n",
        "    dataset_labels_train = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/labels/DS1_labels.csv\",delimiter=\",\")\n",
        "    dataset_labels_train = np.reshape(dataset_labels_train,(len(dataset_labels_train),1))\n",
        "    #cae_id = 'n'\n",
        "    # Variáveis para a configuração da CAE\n",
        "    data_length = len(dataset_train.T) # Tamanho do sinal em número de amostras\n",
        "    kernel_size =  20 # Tamanho do Kernel (Janela) de Convolução\n",
        "    epochs = epochs # Quantidade de Épocas para o Treinamento da Rede\n",
        "    data_dimension = 1 # Dimensão dos Dados\n",
        "    optimizer = 'adamax'\n",
        "    loss = 'mean_squared_error'\n",
        "    min = np.amin(dataset_train)\n",
        "    max = np.amax(dataset_train)\n",
        "    # Divisão da Base de Dados em Grupos de acordo com as classes\n",
        "    #processing = ProcessingData(dataset_train)\n",
        "\n",
        "    cae_id = cae_id # 0 = N, 1 = S, 2 = V, 3 = F e 4[?] = Q\n",
        "    # Treina a Rede N\n",
        "    if cae_id == 0:\n",
        "        train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "        decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede S\n",
        "    elif cae_id == 1:\n",
        "        train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "        decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede V\n",
        "    elif cae_id == 2:\n",
        "        train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "        decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede F    \n",
        "    #elif cae_id == 3:\n",
        "    #    train = RunTrain(data_length, data_dimension, min, max, kernel_size, epochs, optimizer, loss)\n",
        "    #    decoded_original_scale, loss = train.run_cae(dataset_train, dataset_labels_train, cae_id)\n",
        "    # Treina a Rede Q\n",
        "    # Apenas para finalizar a condicional caso entre com algum valor diferente    \n",
        "    else:\n",
        "        pass\n",
        "    # To show CAEs DataFrame with EQM and Epochs    \n",
        "    loss_n_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/ens/results/train/loss_0.csv\",header=None)\n",
        "    loss_s_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/nsv/results/train/loss_1.csv\",header=None)\n",
        "    loss_v_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/nsv/results/train/loss_2.csv\",header=None)\n",
        "    #loss_f_data = pd.read_csv(\"/content/drive/My Drive/colab_apps/results/train/loss_3.csv\",header=None)\n",
        "    loss_n = loss_n_data.iloc[-1]\n",
        "    loss_s = loss_s_data.iloc[-1]\n",
        "    loss_v = loss_v_data.iloc[-1]\n",
        "    #loss_f = loss_f_data.iloc[-1]\n",
        "    loss_n_epochs = len(loss_n_data)\n",
        "    loss_s_epochs = len(loss_s_data)\n",
        "    loss_v_epochs = len(loss_v_data)\n",
        "    #loss_f_epochs = len(loss_f_data)\n",
        "    epochs_values = [loss_n_epochs, loss_s_epochs, loss_v_epochs]\n",
        "    df_train = pd.DataFrame([loss_n, loss_s, loss_v], index=['Rede N', 'Rede S', 'Rede V'])\n",
        "    df_train = df_train.assign(Épocas = epochs_values)\n",
        "    df_train.columns = ['EQM', 'Épocas']\n",
        "    print(df_train.head())\n",
        "    df_train.to_csv('/content/drive/My Drive/colab_apps/nsv/results/train/train_parameters.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU77w3DvwCAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCae(object):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def main(self, first_index, last_index):\n",
        "    startTime = datetime.now()\n",
        "    # Carrega a Base de Dados DS2\n",
        "    dataset_test = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/signals/DS2_signals.csv\",delimiter=\",\")\n",
        "    dataset_labels_test = np.loadtxt(\"/content/drive/My Drive/colab_apps/datasets/ecg/mitdb/mlii_dechazal/labels/DS2_labels.csv\", delimiter=\",\")\n",
        "    dataset_labels_test = np.reshape(dataset_labels_test, (len(dataset_labels_test), 1))\n",
        "    net_type = 4\n",
        "    data_proc = ProcessingData(dataset_test)\n",
        "    dataset_test, dataset_labels_test_num = data_proc.organize_data_labels(dataset_labels_test, net_type, len(dataset_test))\n",
        "    labels_rows, labels_num = np.where(dataset_labels_test < 3)\n",
        "    labels_test = []\n",
        "    for index in range(0, len(labels_rows)):\n",
        "      labels_test.append(dataset_labels_test[labels_rows[index]])\n",
        "    # Carrega os modelos salvos\n",
        "    model_a = load_model('/content/drive/My Drive/colab_apps/ens/models/cae_0.h5')\n",
        "    model_b = load_model('/content/drive/My Drive/colab_apps/nsv/models/cae_1.h5')\n",
        "    model_c = load_model('/content/drive/My Drive/colab_apps/nsv/models/cae_2.h5')\n",
        "    #model_d = load_model('/content/drive/My Drive/colab_apps/models/cae_3.h5')\n",
        "    mode = 1\n",
        "    # Valores de Minimo e Máximo do Conjunto de Dados\n",
        "    max = 1024\n",
        "    min = -1024\n",
        "    # Indices onde se inicia e encerra as amostras para o teste\n",
        "    first_index = first_index\n",
        "    last_index = last_index\n",
        "    # Correção para começar no indice correto da Matriz\n",
        "    initial_index = first_index-1\n",
        "    # Array com quais indices o sistema será testado\n",
        "    data_array = np.arange(initial_index, last_index)\n",
        "    # Instanciamento para a execução das redes\n",
        "    cae = RunTest(dataset_test)\n",
        "    data_save = ProcessingData(dataset_test)\n",
        "    # Execução das Redes\n",
        "    if mode == 0: # Modo Simples\n",
        "        # Matrizes para salvar os resultados\n",
        "        predicted_mat = []\n",
        "        for data_index in data_array:\n",
        "            predicted = cae.run_competitive_cae(data_index, min, max, mode, model_a, model_b, model_c)\n",
        "            predicted_mat.append(predicted)\n",
        "            #print(data_index)\n",
        "        data_save.save_results_test_simple(predicted_mat, first_index, last_index)\n",
        "    elif mode == 1: # Modo Completo\n",
        "        # Matrizes para salvar os resultados\n",
        "        error_mat = []\n",
        "        predicted_mat = []\n",
        "        decoded_mat = []\n",
        "        for data_index in data_array:\n",
        "            predicted, error, decoded = cae.run_competitive_cae(data_index, min, max, mode, model_a, model_b, model_c)\n",
        "            error_mat.append(error)\n",
        "            predicted_mat.append(predicted)\n",
        "            decoded_mat.append(decoded)\n",
        "        # Converte decoded para um array\n",
        "        decoded_array = np.asarray(decoded_mat)\n",
        "        decoded_array = decoded_array.reshape((3, 180))\n",
        "        print(predicted_mat)\n",
        "        print(error_mat)\n",
        "        print(decoded_array)\n",
        "        # Salva os resultados\n",
        "        data_save.save_results_test_full(decoded_array, predicted_mat, error_mat, first_index, last_index)\n",
        "    else:\n",
        "        pass\n",
        "    #print(\"Tempo de Execução = \", datetime.now() - startTime)\n",
        "    # Armazena em um vetor linha as classes originais e as preditas\n",
        "    data_true = labels_test\n",
        "    pred_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/simple/predicted_%s_%s.csv\" %(first_index, last_index)\n",
        "    pred_mat = np.loadtxt(pred_path, delimiter=\",\")\n",
        "    pred_mat = np.reshape(pred_mat, (len(pred_mat), 1))\n",
        "    pred_mat = pred_mat.T\n",
        "    #data_true = data_true.tolist()\n",
        "    pred_mat = pred_mat.tolist()\n",
        "    #data_true = data_true[0]\n",
        "    data_true = data_true[initial_index:last_index]\n",
        "    pred_mat = pred_mat[0]\n",
        "    # Calcula Acurácia, Sensibilidade e +P\n",
        "    accuracy = accuracy_score(data_true, pred_mat)\n",
        "    print('Acc = ', accuracy)\n",
        "    recall = recall_score(data_true, pred_mat, average='macro') \n",
        "    print('Sen = ', recall)\n",
        "    #recall_class = recall_score(data_true, pred_mat, average=None) \n",
        "    #print('Sen_C = ', recall_class)\n",
        "    #precision_class = precision_score(data_true, pred_mat, average=None) \n",
        "    #print('+P = ', precision_class)\n",
        "    precision, recall, fscore, support = score(data_true, pred_mat)\n",
        "    #print('+P: {}'.format(precision))\n",
        "    #print('Sen: {}'.format(recall))\n",
        "    recall_values = [precision[0], precision[1], precision[2]]\n",
        "    df_score = pd.DataFrame([recall[0], recall[1], recall[2]], index=['N', 'S', 'V'])\n",
        "    df_score = df_score.assign(P = recall_values)\n",
        "    df_score.columns = ['Sen', 'P']\n",
        "    print(df_score.head())\n",
        "    #df_test = pd.DataFrame([recall_class[0], recall_class[1], recall_class[2], recall_class[3]], \n",
        "    #                       index=['Classe N', 'Classe S', 'Classe V', 'Classe F'])\n",
        "    #df_test.columns = ['Sen', 'PPV']\n",
        "    #df_test = df_test.assign(PPV = precision_class)\n",
        "    #print(df_test.head())\n",
        "    #df_test.to_csv('/content/drive/My Drive/colab_apps/results/test/test_sen_p.csv')\n",
        "\n",
        "    cf = confusion_matrix(data_true, pred_mat)\n",
        "    #cf_cm = pd.DataFrame(cf, index = [i for i in \"NSVF\"],\n",
        "    #                  columns = [i for i in \"NSVF\"])\n",
        "    #plt.figure(figsize=(6, 6))\n",
        "    #sns_confmat = sns.heatmap(cf_cm, cbar = False, annot=True, fmt='g')\n",
        "    #fig_path = \"/content/drive/My Drive/colab_apps/results/test/confmat_%s_%s.png\" %(first_index, last_index)\n",
        "    #sns_confmat.savefig(fig_path)\n",
        "    classes = ['N','S','V']\n",
        "    plt.imshow(cf, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Matriz de Confusão\")\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cf.max() / 2.\n",
        "    for i, j in itertools.product(range(cf.shape[0]), range(cf.shape[1])):\n",
        "        plt.text(j, i, format(cf[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cf[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('Classes Preditas')\n",
        "    plt.xlabel('Classes Originais')\n",
        "    plt.tight_layout()\n",
        "    fig_path = \"/content/drive/My Drive/colab_apps/nsv/results/test/confmat_%s.png\" %(accuracy)\n",
        "    plt.savefig(fig_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlyfvp7wj0LF",
        "colab_type": "code",
        "outputId": "0d4f9fbe-ea82-4f03-fae3-a77f10b2ebcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "cae_train = TrainCae()\n",
        "cae_train.main(1,7900) # cae_id, epochs. Para 1, o valor ideal do EQM é próximo de 120"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             EQM  Épocas\n",
            "Rede N  0.000124     300\n",
            "Rede S  0.000121    7900\n",
            "Rede V  0.000144     450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Np90cNKjYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cae_test = TestCae()\n",
        "cae_test.main(1906, 1906) #49303"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}